{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ef3b2c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-24T01:58:55.595041Z",
     "iopub.status.busy": "2025-11-24T01:58:55.594784Z",
     "iopub.status.idle": "2025-11-24T01:59:15.516260Z",
     "shell.execute_reply": "2025-11-24T01:59:15.515359Z"
    },
    "papermill": {
     "duration": 19.927811,
     "end_time": "2025-11-24T01:59:15.517688",
     "exception": false,
     "start_time": "2025-11-24T01:58:55.589877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 01:59:00.705848: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763949540.922523      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763949540.991688      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versi TensorFlow: 2.18.0\n",
      "GPU tersedia:  Ya\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORT LIBRARY\n",
    "# ============================================================\n",
    "\n",
    "# --- Library Dasar & Manajemen File ---\n",
    "import os                       # Manajemen path file/folder dataset\n",
    "import glob                     # Pencarian file dengan pola tertentu (misalnya *.jpg)\n",
    "import random                   # Membuat nilai acak (misalnya shuffle dataset)\n",
    "import pandas as pd             # Manipulasi data tabular (CSV, DataFrame)\n",
    "import numpy as np              # Operasi matriks & array (fondasi AI/ML)\n",
    "import math                     # Fungsi matematika kompleks (misalnya log, gamma)\n",
    "import time                     # Mengukur durasi training (timer)\n",
    "\n",
    "# --- Library Visualisasi (Grafik & Plot) ---\n",
    "import matplotlib.pyplot as plt # Membuat grafik akurasi, loss, dll.\n",
    "import seaborn as sns           # Visualisasi heatmap (misalnya confusion matrix)\n",
    "\n",
    "# --- Library Pemrosesan Gambar (Preprocessing) ---\n",
    "import cv2                      # OpenCV: resize, noise removal, membaca gambar\n",
    "from PIL import Image           # Alternatif manipulasi gambar sederhana\n",
    "from sklearn.model_selection import train_test_split  # Membagi dataset (train/test split)\n",
    "from sklearn.model_selection import KFold             # K-Fold Cross Validation\n",
    "\n",
    "# --- Library Deep Learning (Keras/TensorFlow) ---\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model # Membuat model sequential atau custom\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,             # Layer konvolusi untuk ekstraksi fitur\n",
    "    MaxPooling2D,       # Layer pooling untuk reduksi dimensi\n",
    "    Flatten,            # Meratakan array sebelum masuk ke fully connected layer\n",
    "    Dense,              # Fully connected layer (klasifikasi akhir)\n",
    "    Dropout,            # Regularisasi untuk mencegah overfitting\n",
    "    Input,              # Definisi input layer\n",
    "    BatchNormalization, # Normalisasi batch agar training stabil\n",
    "    Activation          # Fungsi aktivasi (ReLU, Softmax, dll.)\n",
    ")\n",
    "from tensorflow.keras.optimizers import SGD            # Optimizer dasar (bisa dituning)\n",
    "from tensorflow.keras.regularizers import l2           # Regularisasi L2 (mencegah overfitting)\n",
    "\n",
    "# --- Library Evaluasi Performa ---\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,       # Matriks kesalahan prediksi per kelas\n",
    "    classification_report,  # Precision, Recall, F1-Score\n",
    "    accuracy_score,         # Akurasi sederhana\n",
    "    roc_curve,              # Kurva ROC (Receiver Operating Characteristic)\n",
    "    auc                     # Area Under Curve (AUC)\n",
    ")\n",
    "\n",
    "# --- Utility Tambahan ---\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Augmentasi data gambar\n",
    "from tensorflow.keras.utils import to_categorical                   # One-hot encoding label\n",
    "\n",
    "# ============================================================\n",
    "# CEK KETERSEDIAAN GPU\n",
    "# ============================================================\n",
    "print(f\"Versi TensorFlow: {tf.__version__}\")  # Menampilkan versi TensorFlow\n",
    "print(\"GPU tersedia: \", \"Ya\" if tf.config.list_physical_devices('GPU') else \"Tidak\")  # Mengecek apakah GPU aktif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7fc4236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T01:59:15.526368Z",
     "iopub.status.busy": "2025-11-24T01:59:15.525923Z",
     "iopub.status.idle": "2025-11-24T01:59:15.817549Z",
     "shell.execute_reply": "2025-11-24T01:59:15.816550Z"
    },
    "papermill": {
     "duration": 0.296967,
     "end_time": "2025-11-24T01:59:15.818618",
     "exception": true,
     "start_time": "2025-11-24T01:59:15.521651",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/2397525248.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Matikan Warning Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 2. Matikan Log TensorFlow yang berisik (INFO & WARNING)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TF_CPP_MIN_LOG_LEVEL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Matikan Warning Python\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 2. Matikan Log TensorFlow yang berisik (INFO & WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "# Level 0 = Semua log muncul\n",
    "# Level 1 = Filter INFO\n",
    "# Level 2 = Filter INFO & WARNING (Kita pilih ini)\n",
    "# Level 3 = Filter ERROR juga\n",
    "\n",
    "print(\"✅ Log Warning berhasil disembunyikan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652339b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:13:56.169169Z",
     "iopub.status.busy": "2025-11-24T00:13:56.168890Z",
     "iopub.status.idle": "2025-11-24T00:13:56.421700Z",
     "shell.execute_reply": "2025-11-24T00:13:56.421126Z",
     "shell.execute_reply.started": "2025-11-24T00:13:56.169149Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BAGIAN 1: PERSIAPAN DATASET (MODIFIKASI 4 KELAS)\n",
    "# ============================================================\n",
    "# Dokumentasi:\n",
    "# Kode ini menggabungkan seluruh data (Training + Testing bawaan dataset)\n",
    "# menjadi satu, lalu split manual 70:30 sesuai metodologi Paper.\n",
    "\n",
    "print(\"\\n--- MENYIAPKAN DATASET 4 KELAS ---\")   # Info proses dimulai\n",
    "\n",
    "# 1. Tentukan Lokasi Dataset \n",
    "DATASET_ROOT = '/kaggle/input/tumorv2'   # Path root dataset (ubah sesuai lokasi dataset)\n",
    "\n",
    "filepaths = []   # List untuk menyimpan path gambar\n",
    "labels = []      # List untuk menyimpan label kelas\n",
    "\n",
    "# 2. Crawling Data (Mencari semua file gambar secara rekursif)\n",
    "# Kita mencari ke dalam folder 'Training' dan 'Testing' sekaligus\n",
    "for category in ['Training', 'Testing']:                  # Loop ke folder Training & Testing\n",
    "    path = os.path.join(DATASET_ROOT, category)           # Gabungkan path root + kategori\n",
    "    \n",
    "    if os.path.exists(path):                              # Jika folder ada\n",
    "        classes = os.listdir(path)                        # Ambil daftar sub-folder (nama kelas)\n",
    "        \n",
    "        for class_name in classes:                        # Loop tiap kelas\n",
    "            class_dir = os.path.join(path, class_name)    # Path ke folder kelas\n",
    "            if os.path.isdir(class_dir):                  # Pastikan benar folder\n",
    "                files = glob.glob(os.path.join(class_dir, '*'))  # Ambil semua file gambar\n",
    "                for f in files:                           # Loop tiap file gambar\n",
    "                    filepaths.append(f)                   # Simpan path gambar\n",
    "                    labels.append(class_name)             # Simpan label kelas\n",
    "    else:\n",
    "        # Jika struktur folder tidak punya 'Training/Testing', coba baca langsung\n",
    "        direct_path = DATASET_ROOT\n",
    "        if os.path.exists(direct_path):                   # Jika folder root ada\n",
    "            classes = [d for d in os.listdir(direct_path) \n",
    "                       if os.path.isdir(os.path.join(direct_path, d))]  # Ambil sub-folder kelas\n",
    "            for class_name in classes:\n",
    "                if class_name in ['Training', 'Testing']: continue      # Skip jika folder Training/Testing\n",
    "                class_dir = os.path.join(direct_path, class_name)       # Path ke folder kelas\n",
    "                files = glob.glob(os.path.join(class_dir, '*'))         # Ambil semua file gambar\n",
    "                for f in files:\n",
    "                    filepaths.append(f)                   # Simpan path gambar\n",
    "                    labels.append(class_name)             # Simpan label kelas\n",
    "\n",
    "# 3. Buat DataFrame & Cek Data\n",
    "df = pd.DataFrame({'filename': filepaths, 'class': labels})   # Buat dataframe dengan kolom filename & class\n",
    "df = df.drop_duplicates(subset=['filename'])                  # Hapus duplikat jika ada\n",
    "\n",
    "# 4. Acak Data (SHUFFLE) - Sangat Penting!\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle data agar distribusi acak\n",
    "\n",
    "# 5. Info Dataset\n",
    "NUM_CLASSES = len(df['class'].unique())                        # Hitung jumlah kelas unik\n",
    "print(f\"Total Data Ditemukan : {len(df)} gambar\")              # Total gambar\n",
    "print(f\"Jumlah Kelas         : {NUM_CLASSES}\")                 # Jumlah kelas\n",
    "print(f\"Nama Kelas           : {df['class'].unique()}\")        # Nama kelas\n",
    "\n",
    "# 6. SPLIT MANUAL 70:30 (Sesuai Paper)\n",
    "if len(df) > 0:\n",
    "    split_idx = int(len(df) * 0.70)                            # Hitung index split 70%\n",
    "    df_train_full = df.iloc[:split_idx]                        # 70% untuk training (optimasi K-Fold)\n",
    "    df_test_final = df.iloc[split_idx:]                        # 30% untuk final testing\n",
    "    \n",
    "    print(f\"\\n--- STATUS PEMBAGIAN DATA (PAPER SPLIT) ---\")\n",
    "    print(f\"Data Training (70%) : {len(df_train_full)} -> Masuk ke 5-Fold CV\")\n",
    "    print(f\"Data Testing (30%)  : {len(df_test_final)} -> Disimpan untuk Evaluasi Akhir\")\n",
    "else:\n",
    "    print(\"❌ ERROR: Tidak ada gambar ditemukan. Cek path 'DATASET_ROOT' Anda!\")  # Jika dataset kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c7e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T14:48:16.517319Z",
     "iopub.status.busy": "2025-11-23T14:48:16.517097Z",
     "iopub.status.idle": "2025-11-23T14:48:35.077455Z",
     "shell.execute_reply": "2025-11-23T14:48:35.076646Z",
     "shell.execute_reply.started": "2025-11-23T14:48:16.517301Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALISASI SAMPEL DATASET (4 KELAS)\n",
    "# ============================================================\n",
    "\n",
    "# 1. Pastikan data sudah siap\n",
    "if 'df_train_full' in globals():                     # Mengecek apakah variabel df_train_full sudah ada\n",
    "    print(\"--- MENAMPILKAN SAMPEL GAMBAR ---\")       # Info bahwa proses visualisasi dimulai\n",
    "\n",
    "    # 2. Buat Generator Sementara (Hanya untuk ambil sampel)\n",
    "    viz_datagen = ImageDataGenerator(rescale=1./255) # Normalisasi pixel ke [0,1] agar lebih stabil\n",
    "\n",
    "    viz_generator = viz_datagen.flow_from_dataframe( # Membuat generator dari dataframe\n",
    "        df_train_full,                               # Dataframe berisi path file & label\n",
    "        x_col='filename',                            # Kolom berisi path gambar\n",
    "        y_col='class',                               # Kolom berisi label kelas\n",
    "        target_size=(128, 128),                      # Resize gambar ke ukuran 128x128\n",
    "        batch_size=9,                                # Ambil 9 gambar sekaligus\n",
    "        class_mode='categorical',                    # Label dalam bentuk one-hot encoding\n",
    "        shuffle=True                                 # Acak urutan gambar agar variatif\n",
    "    )\n",
    "\n",
    "    # 3. Ambil 1 Batch Data\n",
    "    try:\n",
    "        images, labels = next(viz_generator)         # Ambil batch pertama (9 gambar + label)\n",
    "\n",
    "        # Buat Mapping Index ke Nama Kelas\n",
    "        # class_indices: {'glioma':0, 'meningioma':1, ...}\n",
    "        # Dibalik jadi {0:'glioma', 1:'meningioma', ...}\n",
    "        idx_to_label = {v: k for k, v in viz_generator.class_indices.items()}\n",
    "\n",
    "        # 4. Plotting\n",
    "        plt.figure(figsize=(12, 12))                 # Ukuran canvas 12x12 inch\n",
    "\n",
    "        for i in range(min(9, len(images))):         # Loop untuk 9 gambar\n",
    "            ax = plt.subplot(3, 3, i + 1)            # Buat grid 3x3\n",
    "\n",
    "            plt.imshow(images[i])                    # Tampilkan gambar ke subplot\n",
    "\n",
    "            # Ambil Label dari one-hot encoding (contoh: [0,0,1,0] → index 2)\n",
    "            class_idx = np.argmax(labels[i])         # Cari index dengan nilai 1\n",
    "            class_name = idx_to_label[class_idx]     # Konversi index ke nama kelas\n",
    "\n",
    "            plt.title(class_name)                    # Judul subplot = nama kelas\n",
    "            plt.axis(\"off\")                          # Hilangkan axis agar lebih bersih\n",
    "\n",
    "        plt.show()                                   # Tampilkan semua gambar\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal menampilkan gambar: {e}\")      # Jika error, tampilkan pesan\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ ERROR: Variabel 'df_train_full' belum ada.\") # Jika dataset belum disiapkan\n",
    "    print(\"Silakan jalankan kode 'BAGIAN 2: PERSIAPAN DATASET' terlebih dahulu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab1fad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:14:05.117285Z",
     "iopub.status.busy": "2025-11-24T00:14:05.116608Z",
     "iopub.status.idle": "2025-11-24T00:14:05.129170Z",
     "shell.execute_reply": "2025-11-24T00:14:05.128399Z",
     "shell.execute_reply.started": "2025-11-24T00:14:05.117263Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BAGIAN 2: HELPER MATH (NLCMFO UTILS)\n",
    "# ============================================================\n",
    "# Dokumentasi:\n",
    "# Implementasi rumus matematika dari Paper.\n",
    "# 1. levy_flight: Membuat pergerakan 'lompatan jauh' acak untuk eksplorasi.\n",
    "# 2. get_chaotic_value: Peta kekacauan (Sine/Chebyshev) untuk parameter acak.\n",
    "# 3. create_flexible_cnn: Arsitektur CNN ringan (6 layer) sesuai Paper.\n",
    "\n",
    "def levy_flight(beta=1.5):\n",
    "    # Rumus Levy Flight untuk eksplorasi acak\n",
    "    num = math.gamma(1 + beta) * math.sin(math.pi * beta / 2)   # Bagian numerator\n",
    "    den = math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2))  # Bagian denominator\n",
    "    sigma_x = (num / den) ** (1 / beta)                         # Skala distribusi\n",
    "    u = np.random.normal(0, sigma_x)                            # Sampel normal dengan sigma_x\n",
    "    v = np.random.normal(0, 1)                                  # Sampel normal standar\n",
    "    step = 0.05 * u / (abs(v) ** (1 / beta))                    # Langkah Levy Flight\n",
    "    return step                                                 # Return nilai step\n",
    "\n",
    "def get_chaotic_value(map_type, x_old):\n",
    "    # Fungsi untuk menghasilkan nilai chaotic (sine/chebyshev map)\n",
    "    x_new = 0\n",
    "    if map_type == 'sine':                                      # Peta sine\n",
    "        x_new = (4.0 / 4.0) * math.sin(math.pi * x_old)\n",
    "    elif map_type == 'chebyshev':                               # Peta chebyshev\n",
    "        x_new = math.cos(5 * math.acos(x_old))\n",
    "    if x_new == 0: x_new = 0.0001                               # Hindari nilai nol\n",
    "    return abs(x_new)                                           # Return nilai absolut\n",
    "\n",
    "def create_flexible_cnn(width=128, height=128, depth=3, classes=2, l2_reg=0.0001):\n",
    "    \"\"\"\n",
    "    Arsitektur Lightweight CNN 6 Layer (Sesuai Paper)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)                         # Bentuk input gambar\n",
    "    chanDim = -1                                                # Channel terakhir (format TensorFlow)\n",
    "\n",
    "    model.add(Input(shape=inputShape))                          # Input layer\n",
    "\n",
    "    # Blok 1\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", kernel_regularizer=l2(l2_reg))) # Conv layer 32 filter\n",
    "    model.add(BatchNormalization(axis=chanDim)); model.add(Activation(\"relu\"))   # Normalisasi + ReLU\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", kernel_regularizer=l2(l2_reg))) # Conv layer kedua\n",
    "    model.add(BatchNormalization(axis=chanDim)); model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))); model.add(Dropout(0.25))          # Pooling + Dropout\n",
    "\n",
    "    # Blok 2\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_regularizer=l2(l2_reg))) # Conv layer 64 filter\n",
    "    model.add(BatchNormalization(axis=chanDim)); model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=chanDim)); model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))); model.add(Dropout(0.25))\n",
    "\n",
    "    # Blok 3\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(l2_reg))) # Conv layer 128 filter\n",
    "    model.add(BatchNormalization(axis=chanDim)); model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=chanDim)); model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))); model.add(Dropout(0.25))\n",
    "\n",
    "    # Classifier (Fully Connected)\n",
    "    model.add(Flatten())                                          # Meratakan output conv\n",
    "    model.add(Dense(512, kernel_regularizer=l2(l2_reg)))          # Dense layer 512 neuron\n",
    "    model.add(BatchNormalization()); model.add(Activation(\"relu\")); model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes)); model.add(Activation(\"softmax\"))   # Output layer sesuai jumlah kelas\n",
    "\n",
    "    return model                                                  # Return model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78a9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:14:14.633698Z",
     "iopub.status.busy": "2025-11-24T00:14:14.632953Z",
     "iopub.status.idle": "2025-11-24T00:14:14.649031Z",
     "shell.execute_reply": "2025-11-24T00:14:14.648316Z",
     "shell.execute_reply.started": "2025-11-24T00:14:14.633667Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BAGIAN 3: OBJECTIVE FUNCTION (DENGAN EARLY STOPPING)\n",
    "# ============================================================\n",
    "def objective_function_kfold(hyperparameters):\n",
    "    global df_train_full, NUM_CLASSES   # Gunakan dataset training & jumlah kelas dari variabel global\n",
    "    \n",
    "    # Decode Parameter (hyperparameter yang dioptimasi)\n",
    "    lr_val = hyperparameters[0]         # Learning rate\n",
    "    mom_val = hyperparameters[1]        # Momentum untuk SGD\n",
    "    epochs_val = int(hyperparameters[2])# Jumlah maksimum epoch (dibatasi 50)\n",
    "    l2_val = hyperparameters[3]         # Nilai regularisasi L2\n",
    "    \n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)  # K-Fold Cross Validation (5 fold)\n",
    "    fold_accuracies = []                # List untuk menyimpan akurasi tiap fold\n",
    "    \n",
    "    print(f\"\\n>> [UJI PARAMETER] LR={lr_val:.4f}, Mom={mom_val:.4f}, MaxEp={epochs_val}, L2={l2_val:.4f}\")\n",
    "    \n",
    "    # --- DEFINISI EARLY STOPPING ---\n",
    "    # Strategi: hentikan training jika akurasi validasi stagnan 5 epoch\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_accuracy',         # Pantau akurasi validasi\n",
    "        patience=5,                     # Jika stagnan 5 epoch → stop\n",
    "        restore_best_weights=True,      # Ambil bobot terbaik, bukan bobot terakhir\n",
    "        mode='max',                     # Target: akurasi maksimum\n",
    "        verbose=0                       # Silent mode (tidak print log)\n",
    "    )\n",
    "    \n",
    "    # Loop K-Fold\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(df_train_full)):\n",
    "        \n",
    "        tf.keras.backend.clear_session()    # Reset RAM/VRAM sebelum fold dimulai\n",
    "        \n",
    "        train_data = df_train_full.iloc[train_idx]   # Data training untuk fold ini\n",
    "        val_data   = df_train_full.iloc[val_idx]     # Data validasi untuk fold ini\n",
    "        \n",
    "        # Generator untuk training (augmentasi gambar)\n",
    "        train_gen = ImageDataGenerator(\n",
    "            rescale=1./255, rotation_range=30, width_shift_range=0.1,\n",
    "            height_shift_range=0.1, horizontal_flip=True, fill_mode='nearest'\n",
    "        ).flow_from_dataframe(\n",
    "            train_data, x_col='filename', y_col='class',\n",
    "            target_size=(128, 128), batch_size=32,\n",
    "            class_mode='categorical', shuffle=True, verbose=0\n",
    "        )\n",
    "        \n",
    "        # Generator untuk validasi (hanya rescale, tanpa augmentasi)\n",
    "        val_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "            val_data, x_col='filename', y_col='class',\n",
    "            target_size=(128, 128), batch_size=32,\n",
    "            class_mode='categorical', shuffle=False, verbose=0\n",
    "        )\n",
    "        \n",
    "        # Build Model CNN sesuai arsitektur flexible\n",
    "        model = create_flexible_cnn(classes=NUM_CLASSES, l2_reg=l2_val)\n",
    "        opt   = SGD(learning_rate=lr_val, momentum=mom_val)     # Optimizer SGD dengan LR & momentum\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "        \n",
    "        try:\n",
    "            # Train model dengan Early Stopping\n",
    "            history = model.fit(\n",
    "                train_gen, steps_per_epoch=len(train_gen),\n",
    "                validation_data=val_gen, validation_steps=len(val_gen),\n",
    "                epochs=epochs_val,\n",
    "                callbacks=[early_stop],    # Pasang Early Stopping di sini\n",
    "                verbose=0                  # Silent mode\n",
    "            )\n",
    "            best_acc = max(history.history['val_accuracy'])      # Ambil akurasi validasi terbaik\n",
    "            actual_epoch = len(history.history['loss'])          # Epoch terakhir yang dijalankan\n",
    "            # print(f\"   (Fold {fold_idx+1} stop di epoch {actual_epoch}/{epochs_val})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\"); best_acc = 0.0                 # Jika error, akurasi = 0\n",
    "        \n",
    "        fold_accuracies.append(best_acc)                        # Simpan akurasi fold ini\n",
    "        \n",
    "        # Bersihkan memori tiap fold\n",
    "        del model, history, train_gen, val_gen\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Hitung rata-rata akurasi semua fold\n",
    "    avg_acc = np.mean(fold_accuracies)\n",
    "    error_rate = (1.0 - avg_acc) * 100                          # Error rate = 1 - akurasi\n",
    "    \n",
    "    print(f\"   >> Avg Acc: {avg_acc*100:.2f}% | Error: {error_rate:.2f}%\")\n",
    "    gc.collect()\n",
    "    \n",
    "    return error_rate                                           # Return error rate untuk optimasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff49cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T14:48:35.143894Z",
     "iopub.status.busy": "2025-11-23T14:48:35.143536Z",
     "iopub.status.idle": "2025-11-23T14:48:38.475365Z",
     "shell.execute_reply": "2025-11-23T14:48:38.474644Z",
     "shell.execute_reply.started": "2025-11-23T14:48:35.143872Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CEK DATA VISUALISASI (JALANKAN INI UNTUK MELIHAT GAMBAR)\n",
    "# ============================================================\n",
    "\n",
    "# 1. Pastikan DataFrame sudah ada\n",
    "if 'df_train_full' in globals():                           # Mengecek apakah variabel df_train_full sudah tersedia\n",
    "    print(\"--- MENAMPILKAN SAMPEL DATA TRAINING (RGB + AUGMENTASI) ---\")\n",
    "\n",
    "    # 2. Buat Generator Persis seperti saat Training\n",
    "    # Menggunakan parameter augmentasi yang sama (rotasi, shift, flip)\n",
    "    check_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,                                    # Normalisasi pixel ke [0,1]\n",
    "        rotation_range=30,                                 # Rotasi acak hingga 30 derajat\n",
    "        width_shift_range=0.1,                             # Pergeseran horizontal 10%\n",
    "        height_shift_range=0.1,                            # Pergeseran vertikal 10%\n",
    "        horizontal_flip=True,                              # Flip horizontal acak\n",
    "        fill_mode='nearest'                                # Isi piksel kosong dengan nilai terdekat\n",
    "    )\n",
    "    \n",
    "    check_generator = check_datagen.flow_from_dataframe(\n",
    "        df_train_full,                                     # DataFrame berisi path & label\n",
    "        x_col='filename',                                  # Kolom path gambar\n",
    "        y_col='class',                                     # Kolom label kelas\n",
    "        target_size=(128, 128),                            # Resize ke 128x128\n",
    "        batch_size=5,                                      # Ambil 5 gambar saja\n",
    "        class_mode='categorical',                          # Label dalam bentuk one-hot\n",
    "        shuffle=True                                       # Acak urutan gambar\n",
    "    )\n",
    "\n",
    "    # 3. Ambil 1 Batch\n",
    "    try:\n",
    "        images, labels = next(check_generator)             # Ambil batch pertama (5 gambar + label)\n",
    "        \n",
    "        # Cek Dimensi (Harusnya (5, 128, 128, 3))\n",
    "        print(f\"\\n[INFO TEKNIS] Bentuk Data: {images.shape}\")\n",
    "        if images.shape[-1] == 3:                          # Jika channel terakhir = 3 → RGB\n",
    "            print(\"✅ STATUS: Gambar adalah RGB (3 Channel).\")\n",
    "        else:\n",
    "            print(\"⚠️ STATUS: Gambar bukan RGB.\")\n",
    "\n",
    "        # 4. Tampilkan Gambar\n",
    "        plt.figure(figsize=(15, 5))                        # Canvas ukuran 15x5 inch\n",
    "        \n",
    "        # Mapping index ke nama kelas (contoh: 0 → glioma)\n",
    "        idx_to_label = {v: k for k, v in check_generator.class_indices.items()}\n",
    "        \n",
    "        for i in range(min(5, len(images))):               # Loop untuk 5 gambar\n",
    "            ax = plt.subplot(1, 5, i + 1)                  # Buat grid 1 baris, 5 kolom\n",
    "            \n",
    "            plt.imshow(images[i])                          # Tampilkan gambar\n",
    "            \n",
    "            class_idx = np.argmax(labels[i])               # Ambil index kelas dari one-hot\n",
    "            class_name = idx_to_label[class_idx]           # Konversi index ke nama kelas\n",
    "            \n",
    "            plt.title(f\"{class_name}\\n{images[i].shape}\")  # Judul = nama kelas + dimensi gambar\n",
    "            plt.axis(\"off\")                                # Hilangkan axis agar lebih bersih\n",
    "            \n",
    "        plt.tight_layout()                                 # Atur layout agar rapi\n",
    "        plt.show()                                         # Tampilkan semua gambar\n",
    "        \n",
    "        print(\"\\nKeterangan:\")\n",
    "        print(\"- Jika gambar terlihat miring/terpotong, itu efek AUGMENTASI (Rotation/Shift).\")\n",
    "        print(\"- Jika gambar berwarna, berarti mode RGB aktif.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Gagal menampilkan gambar: {e}\")            # Jika error, tampilkan pesan\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ ERROR: Variabel 'df_train_full' belum ada.\") # Jika dataset belum disiapkan\n",
    "    print(\"Silakan jalankan cell 'BAGIAN 2: PERSIAPAN DATASET' terlebih dahulu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29448a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:14:29.186702Z",
     "iopub.status.busy": "2025-11-24T00:14:29.186380Z",
     "iopub.status.idle": "2025-11-24T00:14:29.197870Z",
     "shell.execute_reply": "2025-11-24T00:14:29.197320Z",
     "shell.execute_reply.started": "2025-11-24T00:14:29.186680Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BAGIAN 4: ALGORITMA NLCMFO (DENGAN MEMORY MANAGEMENT)\n",
    "# ============================================================\n",
    "def NLCMFO(objf, lb, ub, dim, N, Max_iteration):\n",
    "    Moth_pos = np.zeros((N, dim))                          # Matriks posisi awal populasi (N ngengat, dim dimensi)\n",
    "    # Inisialisasi posisi awal acak\n",
    "    for i in range(dim): \n",
    "        Moth_pos[:, i] = np.random.uniform(0, 1, N) * (ub[i] - lb[i]) + lb[i]  # Posisi acak dalam batas lb-ub\n",
    "        \n",
    "    Moth_fitness = np.full(N, float(\"inf\"))                # Fitness awal (inf → belum dihitung)\n",
    "    best_flames = np.copy(Moth_pos)                        # Simpan posisi terbaik (flame)\n",
    "    best_flame_fitness = np.zeros(N)                       # Fitness flame terbaik\n",
    "    chaos_val = 0.7                                        # Nilai awal chaos\n",
    "    last_best_score = float(\"inf\")                         # Skor terbaik terakhir\n",
    "    stagnation_counter = 0                                 # Counter stagnasi\n",
    "    current_map = 'sine'                                   # Map chaos default\n",
    "    \n",
    "    Iteration = 1\n",
    "    while Iteration <= Max_iteration:                      # Loop iterasi utama\n",
    "        Flame_no = round(N - Iteration * ((N - 1) / Max_iteration))  # Jumlah flame aktif\n",
    "        print(f\"\\n=== NLCMFO ITERASI {Iteration}/{Max_iteration} ===\")\n",
    "        \n",
    "        # --- EVALUASI POPULASI (Perbaikan Memory Management) ---\n",
    "        for i in range(N):\n",
    "            print(f\"  > Mengevaluasi Moth {i+1} dari {N}...\", end=\"\")\n",
    "            \n",
    "            # Clamping batasan (agar posisi tetap dalam range lb-ub)\n",
    "            for j in range(dim): \n",
    "                Moth_pos[i, j] = np.clip(Moth_pos[i, j], lb[j], ub[j])\n",
    "            \n",
    "            # Jalankan Objective Function untuk menghitung fitness\n",
    "            Moth_fitness[i] = objf(Moth_pos[i, :])\n",
    "            \n",
    "            # Bersihkan RAM setelah evaluasi satu ngengat\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            # time.sleep(1) # Opsional: jeda 1 detik agar OS reclaim memory\n",
    "        \n",
    "        # --- Sorting & Update Flames ---\n",
    "        if Iteration == 1:                                 # Iterasi pertama → langsung sort\n",
    "            I = np.argsort(Moth_fitness)                   # Urutkan fitness\n",
    "            sorted_population = Moth_pos[I, :]             # Populasi terurut\n",
    "            fitness_sorted = np.sort(Moth_fitness)         # Fitness terurut\n",
    "            best_flames = sorted_population                # Simpan flame terbaik\n",
    "            best_flame_fitness = fitness_sorted\n",
    "        else:                                              # Iterasi berikutnya → gabungkan populasi lama & flame\n",
    "            double_pop = np.concatenate((Moth_pos, best_flames), axis=0)\n",
    "            double_fit = np.concatenate((Moth_fitness, best_flame_fitness), axis=0)\n",
    "            I2 = np.argsort(double_fit)                    # Urutkan gabungan\n",
    "            best_flames = double_pop[I2, :][:N]            # Ambil N terbaik\n",
    "            best_flame_fitness = double_fit[I2][:N]\n",
    "            sorted_population = best_flames\n",
    "        \n",
    "        Best_flame_score = best_flame_fitness[0]           # Fitness terbaik saat ini\n",
    "        Best_flame_pos = best_flames[0, :]                 # Posisi terbaik saat ini\n",
    "        \n",
    "        # --- Chaotic Switching ---\n",
    "        if abs(Best_flame_score - last_best_score) < 1e-6: # Jika skor stagnan\n",
    "            stagnation_counter += 1\n",
    "        else:                                              # Jika ada perbaikan\n",
    "            stagnation_counter = 0\n",
    "            last_best_score = Best_flame_score\n",
    "            current_map = 'sine'                           # Reset ke sine map\n",
    "        if stagnation_counter >= 3:                        # Jika stagnasi 3 kali berturut-turut\n",
    "            current_map = 'chebyshev'                      # Ganti ke chebyshev map\n",
    "            print(\"  [INFO] Stagnasi! Ganti Map.\")\n",
    "        \n",
    "        chaos_val = get_chaotic_value(current_map, chaos_val)  # Update nilai chaos\n",
    "        a = -1 + Iteration * ((-1) / Max_iteration)            # Parameter a (kontrol spiral)\n",
    "        w = 2 * math.exp(-((6 * Iteration / Max_iteration) ** 2))  # Parameter w (kontrol bobot)\n",
    "        \n",
    "        # --- Update Posisi Moth ---\n",
    "        for i in range(N):\n",
    "            for j in range(dim):\n",
    "                if i <= Flame_no:                            # Jika masih dalam jumlah flame aktif\n",
    "                    target = sorted_population[i, j]         # Target = flame ke-i\n",
    "                    dist = abs(sorted_population[i, j] - Moth_pos[i, j])\n",
    "                else:                                        # Jika di luar flame aktif\n",
    "                    target = sorted_population[Flame_no, j]  # Target = flame terakhir\n",
    "                    dist = abs(sorted_population[Flame_no, j] - Moth_pos[i, j])\n",
    "                t = abs((a - 1) * chaos_val + 1)             # Parameter spiral\n",
    "                LF = levy_flight(beta=1.5)                   # Levy Flight untuk eksplorasi\n",
    "                spiral = dist * math.exp(1 * t) * math.cos(t * 2 * math.pi)  # Rumus spiral\n",
    "                Moth_pos[i, j] = (w * LF * spiral) + (LF * target)           # Update posisi\n",
    "                \n",
    "        print(f\"  >> Best Error Rate Iterasi ini: {Best_flame_score:.4f}%\")\n",
    "        Iteration += 1\n",
    "        \n",
    "        # Bersihkan memori setelah satu iterasi penuh\n",
    "        gc.collect()\n",
    "    \n",
    "    return Best_flame_pos, Best_flame_score                 # Return posisi & skor terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3cbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T15:15:36.807159Z",
     "iopub.status.busy": "2025-11-23T15:15:36.806546Z",
     "iopub.status.idle": "2025-11-23T20:14:30.520988Z",
     "shell.execute_reply": "2025-11-23T20:14:30.520172Z",
     "shell.execute_reply.started": "2025-11-23T15:15:36.807135Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BAGIAN 7: EKSEKUSI UTAMA (SETTING 4000 DATA)\n",
    "# ============================================================\n",
    "\n",
    "if len(df) > 0:                                           # Pastikan dataset tidak kosong\n",
    "    # 1. Konfigurasi Batas Parameter\n",
    "    lb = [0.001, 0.1, 10, 0.0001]                         # Lower bound: LR, Momentum, Epochs, L2\n",
    "    ub = [0.1, 0.99, 50, 0.01]                            # Upper bound: LR, Momentum, Epochs, L2\n",
    "\n",
    "    # 2. Setting Iterasi \n",
    "    N_population = 10                                     # Jumlah populasi (ngengat)\n",
    "    Max_iterations = 1                                    # Jumlah iterasi optimasi\n",
    "    \n",
    "    print(\"\\n=== MEMULAI PROSES OPTIMASI (NLCMFO + EARLY STOPPING) ===\")\n",
    "    print(f\"Dataset Size: {len(df)} images\")\n",
    "    print(f\"Population: {N_population} | Max Epoch per Training: 50 (dengan Patience=5)\")\n",
    "    \n",
    "    # Bersihkan RAM Awal\n",
    "    tf.keras.backend.clear_session()                      # Reset session TensorFlow\n",
    "    gc.collect()                                          # Garbage collector\n",
    "    \n",
    "    start_time = time.time()                              # Catat waktu mulai\n",
    "    \n",
    "    # Jalankan NLCMFO (optimasi hyperparameter)\n",
    "    best_pos, best_score = NLCMFO(objective_function_kfold, lb, ub, 4, N_population, Max_iterations)\n",
    "    \n",
    "    end_time = time.time()                                # Catat waktu selesai\n",
    "\n",
    "    print(f\"\\n=== HASIL OPTIMASI SELESAI ===\")\n",
    "    print(f\"Durasi: {(end_time - start_time)/60:.2f} Menit\")   # Lama proses optimasi\n",
    "    print(f\"Parameter Terbaik:\")                               # Parameter hasil optimasi\n",
    "    print(f\" - LR      : {best_pos[0]:.5f}\")\n",
    "    print(f\" - Momentum: {best_pos[1]:.5f}\")\n",
    "    print(f\" - Epochs  : {int(best_pos[2])}\")\n",
    "    print(f\" - L2 Reg  : {best_pos[3]:.5f}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # FINAL TEST: TRAIN ULANG DENGAN CHECKPOINT & EARLY STOPPING\n",
    "    # ============================================================\n",
    "    print(\"\\n--- TRAINING MODEL FINAL (70% TRAIN DATA) ---\")\n",
    "    \n",
    "    # Bersihkan RAM sebelum Final Train\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    time.sleep(2)                                         # Jeda 2 detik agar RAM stabil\n",
    "\n",
    "    # Generator untuk training final (augmentasi ringan)\n",
    "    final_train_gen = ImageDataGenerator(\n",
    "        rescale=1./255, rotation_range=30, fill_mode='nearest'\n",
    "    ).flow_from_dataframe(\n",
    "        df_train_full, x_col='filename', y_col='class',\n",
    "        target_size=(128, 128), batch_size=32, \n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    # Generator untuk testing final (hanya rescale)\n",
    "    final_test_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "        df_test_final, x_col='filename', y_col='class',\n",
    "        target_size=(128, 128), batch_size=32, \n",
    "        class_mode='categorical', shuffle=False\n",
    "    )\n",
    "\n",
    "    # Bangun model CNN dengan parameter terbaik hasil optimasi\n",
    "    model_final = create_flexible_cnn(classes=NUM_CLASSES, l2_reg=best_pos[3])\n",
    "    model_final.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=SGD(learning_rate=best_pos[0], momentum=best_pos[1]),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Checkpoint + Early Stopping untuk Final Model\n",
    "    checkpoint_path = \"Best_Model_CNN_NLCMFO.h5\"          # Simpan model terbaik\n",
    "    \n",
    "    callbacks_list = [\n",
    "        ModelCheckpoint(checkpoint_path, monitor='val_accuracy', mode='max', save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True, verbose=1) # Patience lebih longgar\n",
    "    ]\n",
    "\n",
    "    # Train Final Model\n",
    "    history = model_final.fit(\n",
    "        final_train_gen, \n",
    "        epochs=int(best_pos[2]), \n",
    "        validation_data=final_test_gen,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Load Best Model dari checkpoint\n",
    "    print(\"\\n--- MEMUAT KEMBALI BOBOT MODEL TERBAIK ---\")\n",
    "    try:\n",
    "        model_final.load_weights(checkpoint_path)         # Muat bobot terbaik\n",
    "        print(\"✅ Berhasil memuat model terbaik.\")\n",
    "    except:\n",
    "        print(\"⚠️ Load gagal, menggunakan model terakhir.\")\n",
    "\n",
    "    # Evaluasi Akhir pada data test (30% unseen)\n",
    "    print(\"\\n--- EVALUASI FINAL PADA DATA TEST (30% UNSEEN) ---\")\n",
    "    loss, acc = model_final.evaluate(final_test_gen)      # Evaluasi model\n",
    "    print(f\"AKURASI AKHIR (BEST MODEL): {acc*100:.2f}%\")  # Cetak akurasi akhir\n",
    "\n",
    "else:\n",
    "    print(\"Dataset Kosong.\")                              # Jika dataset kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bff163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:16:43.152673Z",
     "iopub.status.busy": "2025-11-24T00:16:43.152363Z",
     "iopub.status.idle": "2025-11-24T00:46:12.830888Z",
     "shell.execute_reply": "2025-11-24T00:46:12.830215Z",
     "shell.execute_reply.started": "2025-11-24T00:16:43.152652Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EKSEKUSI FINAL LANGSUNG (SKIP OPTIMASI)\n",
    "# ============================================================\n",
    "\n",
    "# 1. Parameter manual (ambil dari log terbaik sebelumnya)\n",
    "MANUAL_LR      = 0.08066   # Learning Rate terbaik dari log\n",
    "MANUAL_MOM     = 0.11968   # Momentum terbaik dari log\n",
    "MANUAL_EPOCHS  = 50        # Jumlah epoch terbaik dari log\n",
    "MANUAL_L2      = 0.00180   # Nilai regularisasi L2 terbaik dari log\n",
    "\n",
    "print(\"\\n=== TRAINING FINAL LANGSUNG ===\")\n",
    "print(f\"LR: {MANUAL_LR}, Mom: {MANUAL_MOM}, Ep: {MANUAL_EPOCHS}, L2: {MANUAL_L2}\")\n",
    "print(f\"Train Data : {len(df_train_full)} | Test Data : {len(df_test_final)} | Kelas: {NUM_CLASSES}\")\n",
    "\n",
    "# 2. Bersihkan memori sebelum training\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# 3. Generator untuk training & testing\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255, rotation_range=30, fill_mode='nearest'\n",
    ").flow_from_dataframe(\n",
    "    df_train_full, x_col='filename', y_col='class',\n",
    "    target_size=(128, 128), batch_size=32,\n",
    "    class_mode='categorical', shuffle=True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "    df_test_final, x_col='filename', y_col='class',\n",
    "    target_size=(128, 128), batch_size=32,\n",
    "    class_mode='categorical', shuffle=False\n",
    ")\n",
    "\n",
    "# 4. Bangun & compile model sekali saja\n",
    "model_final = create_flexible_cnn(classes=NUM_CLASSES, l2_reg=MANUAL_L2)\n",
    "model_final.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=SGD(learning_rate=MANUAL_LR, momentum=MANUAL_MOM),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 5. Setup checkpoint\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'Best_Model_Saved_Manual.h5',\n",
    "    monitor='val_accuracy', mode='max',\n",
    "    save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "# 6. Training final\n",
    "history = model_final.fit(\n",
    "    train_gen,\n",
    "    epochs=int(MANUAL_EPOCHS),\n",
    "    validation_data=test_gen,\n",
    "    callbacks=[checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 7. Evaluasi akhir\n",
    "print(\"\\n--- HASIL AKHIR ---\")\n",
    "model_final.load_weights('Best_Model_Saved_Manual.h5')   # Load bobot terbaik\n",
    "loss, acc = model_final.evaluate(test_gen)\n",
    "print(f\"AKURASI FINAL: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40893690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:54:56.473498Z",
     "iopub.status.busy": "2025-11-24T00:54:56.473199Z",
     "iopub.status.idle": "2025-11-24T00:55:08.498512Z",
     "shell.execute_reply": "2025-11-24T00:55:08.497796Z",
     "shell.execute_reply.started": "2025-11-24T00:54:56.473476Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. LOAD WEIGHTS & PREDIKSI \n",
    "# ============================================================\n",
    "\n",
    "# Muat bobot terbaik (pastikan file ada)\n",
    "try:\n",
    "    model_final.load_weights('Best_Model_Saved_Manual.h5')   # Load bobot model terbaik dari file .h5\n",
    "    print(\"✅ Bobot model berhasil dimuat.\")\n",
    "except:\n",
    "    print(\"⚠️ File bobot tidak ditemukan, menggunakan bobot terakhir di memori.\")\n",
    "\n",
    "# Evaluasi skor dasar pada data test\n",
    "print(\"\\n--- EVALUASI DATA TEST ---\")\n",
    "loss, acc = model_final.evaluate(final_test_gen, verbose=0)  # Evaluasi model pada generator test\n",
    "print(f\"AKURASI FINAL: {acc*100:.2f}%\")                      # Cetak akurasi akhir\n",
    "\n",
    "# ============================================================\n",
    "# 2. GENERATE PREDIKSI DETAIL\n",
    "# ============================================================\n",
    "\n",
    "print(\"Sedang menghitung prediksi detail...\")\n",
    "\n",
    "final_test_gen.reset()                                       # Reset generator agar urutan data konsisten\n",
    "\n",
    "y_pred_probs = model_final.predict(final_test_gen, verbose=1) # Ambil probabilitas prediksi (softmax output)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)             # Ambil kelas prediksi (index probabilitas tertinggi)\n",
    "\n",
    "y_true = final_test_gen.classes                              # Label asli (ground truth)\n",
    "\n",
    "class_names = list(final_test_gen.class_indices.keys())      # Nama kelas (misalnya: glioma, meningioma, dll)\n",
    "\n",
    "# ============================================================\n",
    "# 3. HITUNG METRIK (TERMASUK SPECIFICITY)\n",
    "# ============================================================\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)                # Hitung confusion matrix\n",
    "\n",
    "# Fungsi untuk menghitung specificity multi-class\n",
    "def calculate_specificity(cm):\n",
    "    specificities = []\n",
    "    for i in range(len(cm)):\n",
    "        tn = np.sum(cm) - (np.sum(cm[i, :]) + np.sum(cm[:, i]) - cm[i, i]) # True Negative\n",
    "        fp = np.sum(cm[:, i]) - cm[i, i]                                   # False Positive\n",
    "        spec = tn / (tn + fp) if (tn + fp) > 0 else 0                      # Rumus specificity\n",
    "        specificities.append(spec)\n",
    "    return np.mean(specificities)                                          # Rata-rata specificity semua kelas\n",
    "\n",
    "# Hitung metrik utama\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)                          # Akurasi\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_classes, average='macro')\n",
    "specificity = calculate_specificity(cm)                                    # Specificity\n",
    "\n",
    "# Buat tabel metrik\n",
    "metrics_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall (Sensitivity)', 'Specificity', 'F1-Score'],\n",
    "    'Score': [accuracy, precision, recall, specificity, f1]\n",
    "})\n",
    "metrics_table['Score (%)'] = metrics_table['Score'].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "\n",
    "print(\"\\n=== TABEL PERFORMA LENGKAP ===\")\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(metrics_table.to_html(index=False, classes='table table-striped'))) # Tampilkan tabel rapi\n",
    "\n",
    "# ============================================================\n",
    "# 4. VISUALISASI CONFUSION MATRIX\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',          # Heatmap confusion matrix\n",
    "            xticklabels=class_names,                        # Label kolom = nama kelas prediksi\n",
    "            yticklabels=class_names)                        # Label baris = nama kelas asli\n",
    "plt.xlabel('Prediksi Model (Predicted)')\n",
    "plt.ylabel('Label Asli (Actual)')\n",
    "plt.title('Confusion Matrix (4 Kelas)')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 5. VISUALISASI ROC CURVE (MULTI-CLASS)\n",
    "# ============================================================\n",
    "\n",
    "lb = LabelBinarizer()                                       # Binarize label untuk ROC (One-vs-Rest)\n",
    "y_true_bin = lb.fit_transform(y_true)\n",
    "n_classes = len(class_names)\n",
    "\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()                  # Dictionary untuk FPR, TPR, AUC\n",
    "\n",
    "for i in range(n_classes):                                  # Hitung ROC tiap kelas\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = cycle(['blue', 'red', 'green', 'orange', 'purple']) # Warna berbeda tiap kelas\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC {0} (AUC = {1:0.4f})'.format(class_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)                       # Garis diagonal baseline\n",
    "plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) - Multi-Class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc1ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:56:52.772757Z",
     "iopub.status.busy": "2025-11-24T00:56:52.772432Z",
     "iopub.status.idle": "2025-11-24T00:56:52.803151Z",
     "shell.execute_reply": "2025-11-24T00:56:52.802581Z",
     "shell.execute_reply.started": "2025-11-24T00:56:52.772735Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANALISIS PERFORMA PER KELAS (DETIL)\n",
    "# ============================================================\n",
    "\n",
    "print(\"--- LAPORAN PERFORMA PER KELAS ---\")\n",
    "\n",
    "# 1. Generate Report Dictionary\n",
    "# Output berupa dictionary agar bisa kita olah jadi Tabel\n",
    "report_dict = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "\n",
    "# 2. Buat DataFrame dari Report\n",
    "df_per_class = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# 3. Hitung Specificity Per Kelas\n",
    "# Specificity = TN / (TN + FP)\n",
    "# Rumus: Kemampuan menghindari False Alarm pada kelas tersebut\n",
    "class_specificities = []\n",
    "for i in range(len(cm)):\n",
    "    tn = np.sum(np.delete(np.delete(cm, i, 0), i, 1)) \n",
    "    fp = np.sum(np.delete(cm[:, i], i))\n",
    "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    class_specificities.append(spec)\n",
    "\n",
    "# 4. Rapikan Tabel\n",
    "# Ambil hanya baris kelas (buang baris 'accuracy', 'macro avg', 'weighted avg' sementara)\n",
    "df_classes = df_per_class.loc[class_names].copy()\n",
    "\n",
    "# Masukkan kolom Specificity\n",
    "df_classes['specificity'] = class_specificities\n",
    "\n",
    "# Urutkan kolom agar enak dibaca\n",
    "df_classes = df_classes[['precision', 'recall', 'specificity', 'f1-score', 'support']]\n",
    "\n",
    "# Rename kolom biar lebih cantik\n",
    "df_classes.columns = ['Precision', 'Sensitivity (Recall)', 'Specificity', 'F1-Score', 'Jumlah Data']\n",
    "\n",
    "# Format angka menjadi persentase\n",
    "for col in ['Precision', 'Sensitivity (Recall)', 'Specificity', 'F1-Score']:\n",
    "    df_classes[col] = df_classes[col].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "\n",
    "# Tampilkan Tabel\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(df_classes.to_html(classes='table table-striped table-hover')))\n",
    "\n",
    "print(\"\\nKeterangan:\")\n",
    "print(\"- Sensitivity (Recall): Seberapa hebat model menemukan tumor jenis ini.\")\n",
    "print(\"- Specificity: Seberapa hebat model tidak salah tuduh (misal: Pituitary dibilang Glioma).\")\n",
    "print(\"- Support: Jumlah gambar asli untuk kelas tersebut di data test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0c906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T01:06:04.036603Z",
     "iopub.status.busy": "2025-11-24T01:06:04.036286Z",
     "iopub.status.idle": "2025-11-24T01:06:04.541902Z",
     "shell.execute_reply": "2025-11-24T01:06:04.541110Z",
     "shell.execute_reply.started": "2025-11-24T01:06:04.036581Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNGSI GRAD-CAM \n",
    "# ============================================================\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # 1. Buat Input Baru (Bersih)\n",
    "    grad_model_input = tf.keras.Input(shape=(128, 128, 3))   # Input layer baru agar tidak warning\n",
    "\n",
    "    # 2. Alirkan Input Baru ke Layer Lama (Re-Connect)\n",
    "    x = grad_model_input\n",
    "    last_conv_layer_output = None\n",
    "    \n",
    "    for layer in model.layers:                               # Loop semua layer model\n",
    "        if isinstance(layer, tf.keras.layers.InputLayer):    # Skip InputLayer lama\n",
    "            continue\n",
    "        x = layer(x)                                         # Sambungkan layer ke input baru\n",
    "        if layer.name == last_conv_layer_name:               # Jika layer = conv terakhir\n",
    "            last_conv_layer_output = x                       # Simpan output conv terakhir\n",
    "    \n",
    "    grad_model_output = x                                    # Output akhir model\n",
    "\n",
    "    # 3. Buat Model Grad-CAM Baru\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=grad_model_input,\n",
    "        outputs=[last_conv_layer_output, grad_model_output]  # Model keluarkan conv terakhir + prediksi\n",
    "    )\n",
    "\n",
    "    # 4. Hitung Gradien\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_output, preds = grad_model(img_array)      # Forward pass\n",
    "        if pred_index is None:                               # Jika index kelas belum ditentukan\n",
    "            pred_index = tf.argmax(preds[0])                 # Ambil kelas prediksi tertinggi\n",
    "        class_channel = preds[:, pred_index]                 # Ambil channel prediksi kelas target\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_output)   # Hitung gradien terhadap conv terakhir\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))     # Rata-rata gradien per filter\n",
    "    \n",
    "    last_conv_output = last_conv_output[0]                   # Ambil output conv untuk gambar pertama\n",
    "    heatmap = last_conv_output @ pooled_grads[..., tf.newaxis] # Kombinasi gradien + feature map\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # 5. Normalisasi Heatmap\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap) # Normalisasi ke [0,1]\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# ============================================================\n",
    "# 3. FUNGSI VISUALISASI (DENGAN DETEKSI LAYER OTOMATIS)\n",
    "# ============================================================\n",
    "def display_gradcam_with_barplot(img_path):\n",
    "    # --- A. Preprocessing ---\n",
    "    img = cv2.imread(img_path)                               # Baca gambar\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)           # Konversi ke RGB\n",
    "    img_resized = cv2.resize(img_rgb, (128, 128))            # Resize ke 128x128\n",
    "    img_tensor = np.expand_dims(img_resized.astype('float32') / 255.0, axis=0) # Normalisasi + batch\n",
    "\n",
    "    # --- B. Cari Layer Konvolusi Terakhir ---\n",
    "    last_conv_layer_name = None\n",
    "    for layer in reversed(model_final.layers):               # Loop layer dari belakang\n",
    "        if 'conv' in layer.name.lower():                     # Cari layer conv terakhir\n",
    "            last_conv_layer_name = layer.name\n",
    "            break\n",
    "\n",
    "    # --- C. Prediksi & Heatmap ---\n",
    "    heatmap = make_gradcam_heatmap(img_tensor, model_final, last_conv_layer_name) # Buat heatmap\n",
    "    preds = model_final.predict(img_tensor, verbose=0)       # Prediksi probabilitas\n",
    "    pred_idx = np.argmax(preds[0])                           # Index kelas prediksi\n",
    "    confidence = preds[0][pred_idx]                          # Confidence score\n",
    "    class_names = list(final_test_gen.class_indices.keys())  # Nama kelas dari generator\n",
    "    pred_label = class_names[pred_idx]                       # Label prediksi\n",
    "\n",
    "    # --- D. Tampilkan (Overlay & Plot) ---\n",
    "    heatmap_resized = cv2.resize(heatmap, (img_rgb.shape[1], img_rgb.shape[0])) # Resize heatmap\n",
    "    heatmap_uint8 = np.uint8(255 * heatmap_resized)          # Konversi ke uint8\n",
    "    heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET) # Warna heatmap\n",
    "    overlay = cv2.addWeighted(img_rgb, 0.6, heatmap_colored, 0.4, 0)     # Overlay ke gambar asli\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Gambar 1: Grad-CAM Overlay\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(f\"Prediksi: {pred_label.upper()} ({confidence*100:.2f}%)\")\n",
    "    plt.axis('off')\n",
    "    plt.xlabel(\"Area Merah = Fitur Kunci\")\n",
    "\n",
    "    # Gambar 2: Bar Plot Probabilitas\n",
    "    plt.subplot(1, 2, 2)\n",
    "    colors = ['lightgray'] * len(class_names)\n",
    "    is_tumor = 'normal' not in pred_label.lower() and 'no' not in pred_label.lower()\n",
    "    colors[pred_idx] = 'red' if is_tumor else 'green'        # Warna merah jika tumor, hijau jika normal\n",
    "    \n",
    "    y = np.arange(len(class_names))\n",
    "    plt.barh(y, preds[0], color=colors)                      # Bar plot probabilitas\n",
    "    plt.yticks(y, class_names)\n",
    "    plt.xlim(0, 1.0)\n",
    "    plt.title(\"Probabilitas Model\")\n",
    "    \n",
    "    for i, v in enumerate(preds[0]):                         # Tambahkan nilai % di bar plot\n",
    "        plt.text(v + 0.01, i, f\"{v*100:.1f}%\", va='center', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 4. EKSEKUSI\n",
    "# ============================================================\n",
    "if len(df_test_final) > 0:\n",
    "    random_row = df_test_final.sample(1).iloc[0]             # Ambil 1 sample random dari test set\n",
    "    target_path = random_row['filename']                     # Path gambar\n",
    "    label_asli = random_row['class']                         # Label asli\n",
    "    \n",
    "    print(f\"--- ANALISIS GRAD-CAM ---\")\n",
    "    print(f\"File: {target_path}\")\n",
    "    print(f\"Label Asli: {label_asli}\")\n",
    "    \n",
    "    display_gradcam_with_barplot(target_path)                # Tampilkan hasil Grad-CAM\n",
    "else:\n",
    "    display_gradcam_with_barplot(IMAGE_PATH)                 # Fallback ke path manual jika test kosong"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8806397,
     "sourceId": 13827782,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.944924,
   "end_time": "2025-11-24T01:59:18.885808",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-24T01:58:51.940884",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
